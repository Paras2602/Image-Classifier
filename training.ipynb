{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0382f3e9-fb70-46b0-9a83-b73e726bd625",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q numpy pillow tqdm scikit-learn matplotlib streamlit\n",
    "!pip install -q --index-url https://download.pytorch.org/whl/cpu torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14cf7dad-4053-4562-80f9-7dce884814b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1587095f-f271-4810-85ee-22207fde9e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "Sizes  : train = 45000 val = 5000 test = 10000\n",
      "Batches: 704 79 157\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "DATA_DIR = \"./data\"\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 0  # Windows/Jupyter safe\n",
    "PIN_MEMORY = torch.cuda.is_available()  # True only if CUDA\n",
    "\n",
    "# CIFAR-10 normalization\n",
    "CIFAR_MEAN = (0.4914, 0.4822, 0.4465)\n",
    "CIFAR_STD  = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "train_tfms = T.Compose([\n",
    "    T.RandomCrop(32, padding=4),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(CIFAR_MEAN, CIFAR_STD),\n",
    "])\n",
    "\n",
    "eval_tfms = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(CIFAR_MEAN, CIFAR_STD),\n",
    "])\n",
    "\n",
    "# Two datasets so validation does NOT use random augmentations\n",
    "train_full = torchvision.datasets.CIFAR10(root=DATA_DIR, train=True,  download=True,  transform=train_tfms)\n",
    "val_full   = torchvision.datasets.CIFAR10(root=DATA_DIR, train=True,  download=False, transform=eval_tfms)\n",
    "test_ds    = torchvision.datasets.CIFAR10(root=DATA_DIR, train=False, download=True,  transform=eval_tfms)\n",
    "\n",
    "CLASS_NAMES = train_full.classes\n",
    "\n",
    "# Reproducible split\n",
    "val_size = 5000\n",
    "n = len(train_full)\n",
    "g = torch.Generator().manual_seed(42)\n",
    "perm = torch.randperm(n, generator=g).tolist()\n",
    "\n",
    "val_idx = perm[:val_size]\n",
    "train_idx = perm[val_size:]\n",
    "\n",
    "train_ds = Subset(train_full, train_idx)\n",
    "val_ds   = Subset(val_full, val_idx)\n",
    "\n",
    "dl_kwargs = dict(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY,\n",
    ")\n",
    "\n",
    "# (persistent_workers must be False when NUM_WORKERS=0)\n",
    "if NUM_WORKERS > 0:\n",
    "    dl_kwargs[\"persistent_workers\"] = True\n",
    "\n",
    "train_loader = DataLoader(train_ds, shuffle=True,  **dl_kwargs)\n",
    "val_loader   = DataLoader(val_ds,   shuffle=False, **dl_kwargs)\n",
    "test_loader  = DataLoader(test_ds,  shuffle=False, **dl_kwargs)\n",
    "\n",
    "print(\"Classes:\", CLASS_NAMES)\n",
    "print(\"Sizes  : train =\", len(train_ds), \"val =\", len(val_ds), \"test =\", len(test_ds))\n",
    "print(\"Batches:\", len(train_loader), len(val_loader), len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c255e0d2-5a34-4a6c-bab4-0f34897240bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 4 * 4, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.features(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21d13f65-652f-482b-abe2-d1118cb9f96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_accuracy(model, loader, device):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        preds = model(x).argmax(1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    return correct / max(total, 1)\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss, total = 0.0, 0\n",
    "\n",
    "    pbar = tqdm(loader, desc=\"train\", leave=False)\n",
    "    for x, y in pbar:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        bs = y.size(0)\n",
    "        total_loss += loss.item() * bs\n",
    "        total += bs\n",
    "\n",
    "        pbar.set_postfix(loss=float(loss.item()))\n",
    "\n",
    "    return total_loss / max(total, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6962dbfb-cf20-4c01-839f-dd63b89594ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8baf5001ba14da9b57cddd9463b23f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/704 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 01 | loss=1.6887 | val_acc=0.6008 | best=0.6008\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c1c8c448e441a0b67558b65b3c1477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/704 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 02 | loss=1.4377 | val_acc=0.6606 | best=0.6606\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c7065203ee45b2bb5ed9a8e6ab8f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/704 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 03 | loss=1.3500 | val_acc=0.6876 | best=0.6876\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f30cdb9d2248b088efa0a919c6900d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/704 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 04 | loss=1.2871 | val_acc=0.7152 | best=0.7152\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c6dcbffb07c4d0c9927d5efc0586ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/704 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 05 | loss=1.2430 | val_acc=0.7260 | best=0.7260\n",
      "Saved: models/baseline_best.pt\n"
     ]
    }
   ],
   "source": [
    "Path(\"models\").mkdir(exist_ok=True)\n",
    "\n",
    "baseline = SimpleCNN(num_classes=10).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(baseline.parameters(), lr=1e-3, weight_decay=5e-4)\n",
    "\n",
    "EPOCHS_BASELINE = 5\n",
    "best_val = 0.0\n",
    "\n",
    "for epoch in range(1, EPOCHS_BASELINE + 1):\n",
    "    loss = train_one_epoch(baseline, train_loader, optimizer, criterion, device)\n",
    "    val_acc = eval_accuracy(baseline, val_loader, device)\n",
    "\n",
    "    if val_acc > best_val:\n",
    "        best_val = val_acc\n",
    "        torch.save({\"model_state\": baseline.state_dict()}, \"models/baseline_best.pt\")\n",
    "\n",
    "    print(f\"[Baseline] Epoch {epoch:02d} | loss={loss:.4f} | val_acc={val_acc:.4f} | best={best_val:.4f}\")\n",
    "\n",
    "print(\"Saved: models/baseline_best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55e8a54e-7703-47f7-9be4-873a016a056d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet loaders ready: 704 79 157\n"
     ]
    }
   ],
   "source": [
    "INPUT_SIZE = 224\n",
    "IMNET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMNET_STD  = (0.229, 0.224, 0.225)\n",
    "\n",
    "train_tfms_rn = T.Compose([\n",
    "    T.Resize(INPUT_SIZE),\n",
    "    T.RandomResizedCrop(INPUT_SIZE, scale=(0.8, 1.0)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(IMNET_MEAN, IMNET_STD),\n",
    "])\n",
    "\n",
    "eval_tfms_rn = T.Compose([\n",
    "    T.Resize(INPUT_SIZE),\n",
    "    T.CenterCrop(INPUT_SIZE),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(IMNET_MEAN, IMNET_STD),\n",
    "])\n",
    "\n",
    "train_full_rn = torchvision.datasets.CIFAR10(root=DATA_DIR, train=True, download=True, transform=train_tfms_rn)\n",
    "val_full_rn   = torchvision.datasets.CIFAR10(root=DATA_DIR, train=True, download=False, transform=eval_tfms_rn)\n",
    "test_ds_rn    = torchvision.datasets.CIFAR10(root=DATA_DIR, train=False, download=True, transform=eval_tfms_rn)\n",
    "\n",
    "# same split indices sizes as baseline\n",
    "n = len(train_full_rn)\n",
    "perm = torch.randperm(n, generator=torch.Generator().manual_seed(42)).tolist()\n",
    "val_idx = perm[:val_size]\n",
    "train_idx = perm[val_size:]\n",
    "\n",
    "train_ds_rn = Subset(train_full_rn, train_idx)\n",
    "val_ds_rn   = Subset(val_full_rn, val_idx)\n",
    "\n",
    "train_loader_rn = DataLoader(train_ds_rn, batch_size=BATCH_SIZE, shuffle=True,  num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "val_loader_rn   = DataLoader(val_ds_rn,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "test_loader_rn  = DataLoader(test_ds_rn,  batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "\n",
    "print(\"ResNet loaders ready:\", len(train_loader_rn), len(val_loader_rn), len(test_loader_rn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4b60868-94ef-4862-8556-a8cebc57810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "\n",
    "# Freeze backbone (CPU fast)\n",
    "for name, param in model.named_parameters():\n",
    "    if not name.startswith(\"fc.\"):\n",
    "        param.requires_grad = False\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion_rn = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer_rn = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                           lr=3e-4, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b6cc831-563a-4456-99b5-33fe676df54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae43467d6ee24f8f88a5a33017452806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/704 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResNet18-Frozen] Epoch 01 | loss=1.3995 | val_acc=0.7688 | best=0.7688\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a8b305ca67f473e8315da6dd3341335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/704 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResNet18-Frozen] Epoch 02 | loss=1.1229 | val_acc=0.7834 | best=0.7834\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94f7d9093a1449e9db3153021b4162b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/704 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResNet18-Frozen] Epoch 03 | loss=1.0909 | val_acc=0.7968 | best=0.7968\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca7a4083df294f96bf706435cbcfa45e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/704 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResNet18-Frozen] Epoch 04 | loss=1.0713 | val_acc=0.7944 | best=0.7968\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c21a910bbc9049b1b12352797c5d3a2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/704 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResNet18-Frozen] Epoch 05 | loss=1.0615 | val_acc=0.8056 | best=0.8056\n",
      "Saved checkpoint: models/cifar10_resnet18_best.pt\n"
     ]
    }
   ],
   "source": [
    "Path(\"models\").mkdir(exist_ok=True)\n",
    "ckpt_path = \"models/cifar10_resnet18_best.pt\"\n",
    "\n",
    "EPOCHS_RESNET = 5\n",
    "best_val = 0.0\n",
    "\n",
    "for epoch in range(1, EPOCHS_RESNET + 1):\n",
    "    loss = train_one_epoch(model, train_loader_rn, optimizer_rn, criterion_rn, device)\n",
    "    val_acc = eval_accuracy(model, val_loader_rn, device)\n",
    "\n",
    "    if val_acc > best_val:\n",
    "        best_val = val_acc\n",
    "        ckpt = {\n",
    "            \"model_name\": \"resnet18\",\n",
    "            \"num_classes\": 10,\n",
    "            \"class_names\": CLASS_NAMES,\n",
    "            \"input_size\": INPUT_SIZE,\n",
    "            \"norm_mean\": IMNET_MEAN,\n",
    "            \"norm_std\": IMNET_STD,\n",
    "            \"model_state\": model.state_dict(),\n",
    "        }\n",
    "        torch.save(ckpt, ckpt_path)\n",
    "\n",
    "    print(f\"[ResNet18-Frozen] Epoch {epoch:02d} | loss={loss:.4f} | val_acc={val_acc:.4f} | best={best_val:.4f}\")\n",
    "\n",
    "print(f\"Saved checkpoint: {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff59590f-9e3a-40ba-bb83-cd693866c0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample images to sample_images/\n"
     ]
    }
   ],
   "source": [
    "Path(\"sample_images\").mkdir(exist_ok=True)\n",
    "\n",
    "raw_test = torchvision.datasets.CIFAR10(root=DATA_DIR, train=False, download=True)\n",
    "for i in range(20):\n",
    "    img, label = raw_test[i]\n",
    "    name = raw_test.classes[label]\n",
    "    img.save(f\"sample_images/{i:02d}_{name}.png\") \n",
    "\n",
    "print(\"Saved sample images to sample_images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750ed049-4c8a-41f1-bd8d-6da33a1e74eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
